{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = 'xyx_train.py --name xyx_10 --checkpoints_dir ./checkpoints --output_nc 20 --dataset cityscapesAB ' \\\n",
    "        + '--batchSize 4 --heightSize 224 --widthSize 224 --start_epoch 0 --niter 200 ' \\\n",
    "        + '--drop_lr 5 --resize_or_crop crop --ignore_index 0 --unsup_portion 89 --portion_total 90 ' \\\n",
    "        + '--unsup_sampler sep --port 1235 --gpu_ids 1'\n",
    "sys.argv = sys.argv.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(archD='patch', archF='style_transform', archG='style_transform', batchSize=4, beta1=0.5, checkpoints_dir='./checkpoints', dataset='cityscapesAB', display_id=1, display_winsize=256, drop_lr=5, gpu_ids='1', heightSize=224, ignore_index=0, input_nc=3, isTrain=True, lambda_x=1.0, lambda_y=1.0, lr=0.0002, lrFGD={'F': 0.0001, 'G': 0.0001, 'D': 0.0001}, manual_seed=123, nThreads=4, n_layers_D=3, n_layers_F=9, n_layers_G=9, name='xyx_10_cityscapesAB_b4/stageF:2,G:0,D:0/lrFGD1e-4,1e-4,1e-4_lbX1.0e+00', ndf=64, ngf=64, niter=200, niter_decay=100, no_flip=False, no_html=False, noise='sphere', nz=100, output_nc=20, port=1235, portion_total=90, resize_or_crop='crop', save_every=2, stage='F:2,G:0,D:0', start_epoch=0, unsup_portion=89, unsup_sampler='sep', updates={'F': 2, 'G': 0, 'D': 0}, use_dropout=False, which_direction='AtoB', widthSize=224)\n"
     ]
    }
   ],
   "source": [
    "from xyx_nets import *\n",
    "\n",
    "opt = get_opt()\n",
    "print(opt)\n",
    "\n",
    "# gpu id\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_ids # absolute ids\n",
    "if len(opt.gpu_ids) > 0:\n",
    "    torch.randn(8).cuda()\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "opt.gpu_ids = range(0,len(opt.gpu_ids)) # new range starting from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xyx_10_cityscapesAB_b4\n"
     ]
    }
   ],
   "source": [
    "name_temp1 = '%s/stage%s/lrFGD%s_lbX%.3f'\n",
    "name_temp2 = '%s/stage%s/lrFGD%s_lbX%.1e'\n",
    "exp_folder = opt.name.split('/')[0]\n",
    "print(exp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses\n",
    "CE, L1 = create_losses(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> dataset [CityscapesABDataset] was created\n"
     ]
    }
   ],
   "source": [
    "# data_loaders\n",
    "from data.data_loader import CreateDataLoader,InfiniteDataLoader,XYDataLoader\n",
    "from util.visualizer import Visualizer\n",
    "\n",
    "opt.phase = 'val'\n",
    "opt.isTrain = False\n",
    "val_loader = CreateDataLoader(opt)\n",
    "opt = val_loader.update_opt(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networks\n",
    "TAU0 = 1.0\n",
    "\n",
    "net =dict()\n",
    "net['F'] = FX2Y(opt, temperature=TAU0)\n",
    "net['G'] = GY2X(opt)\n",
    "net['D'] = NLayerDiscriminator(opt)\n",
    "\n",
    "for k in net.keys():\n",
    "    if len(opt.gpu_ids) > 0:\n",
    "        net[k].cuda(opt.gpu_ids[0])\n",
    "    # F has its own init\n",
    "    if k != 'F':\n",
    "        net[k].apply(weights_init)\n",
    "\n",
    "def load_nets(ckpt_path):\n",
    "    for k in net.keys():\n",
    "        # load if found saved weights\n",
    "        weights_fpath = os.path.join(ckpt_path, 'net%s.pth' % (k))\n",
    "        if os.path.exists(weights_fpath):\n",
    "            print('Load net[%s] from %s' % (k, weights_fpath))\n",
    "            net[k].load_state_dict(torch.load(weights_fpath, map_location=lambda storage, loc: storage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.meter import SegmentationMeter\n",
    "def evaluation(epoch, do_G=False, subset='train'):\n",
    "    heightSize = val_loader.dataset.heightSize\n",
    "    widthSize = val_loader.dataset.widthSize\n",
    "    xx = torch.FloatTensor(1, opt.input_nc, heightSize, widthSize)\n",
    "    yy_int = torch.LongTensor(1, heightSize, widthSize)\n",
    "    if len(opt.gpu_ids) > 0:\n",
    "        xx = xx.cuda(opt.gpu_ids[0])\n",
    "        yy_int = yy_int.cuda(opt.gpu_ids[0])\n",
    "\n",
    "    net['F'].eval()\n",
    "    if do_G:\n",
    "        net['G'].eval()\n",
    "\n",
    "    eval_stats = SegmentationMeter(n_class=opt.output_nc, ignore_index=opt.ignore_index)\n",
    "    E_loss_CE = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    val_loader_iter = iter(val_loader)\n",
    "    for i in range(len(val_loader)):\n",
    "        populate_xy(xx, yy_int, val_loader_iter, opt)\n",
    "        v_x = Variable(xx, volatile=True)\n",
    "        v_y_int = Variable(yy_int, volatile=True)\n",
    "        y_hat = net['F'](v_x)\n",
    "        E_loss_CE.append( CE(y_hat, v_y_int) )\n",
    "        logits = y_hat.data.cpu().numpy()\n",
    "        pred = logits.argmax(1) # NCHW -> NHW\n",
    "        gt = yy_int.cpu().numpy()\n",
    "        eval_stats.update_confmat(gt, pred)\n",
    "\n",
    "        if do_G:\n",
    "            x_tilde = net['G'](y_hat) # x -> y_hat -> x_tilde\n",
    "\n",
    "        # visualization\n",
    "        if i % 10 == 0:\n",
    "            images = {'TEST_x':v_x.data.cpu(),\n",
    "                      'TEST_y':v_y_int.data.cpu().numpy(), 'TEST_y_hat':y_hat.data.cpu().numpy().argmax(1)}\n",
    "            if do_G:\n",
    "                images['TEST_x_tilde'] = x_tilde.data.cpu()\n",
    "            display_imgs(images, epoch, i, subset=subset, do_save=2)\n",
    "\n",
    "    print('EVAL at epoch %d ==> average CE = %.3f' % (epoch, sum(E_loss_CE).data[0] / len(val_loader)))\n",
    "    eval_results = eval_stats.get_eval_results()\n",
    "    msg = 'EVAL at epoch %d [%d images in %.2f sec] ==> %s\\n' % \\\n",
    "                (epoch, len(val_loader), time.time()-start_time, eval_results[0])\n",
    "    msg += 'Per-class IoU:\\n'\n",
    "    msg += ''.join(['%s: %.2f\\n' % (cname,ciu)\n",
    "                    for cname,ciu in zip(val_loader.dataset.label2name, eval_results[1])])\n",
    "    print(msg)\n",
    "    with open(visualizer.log_name, \"a\") as log_file:\n",
    "        log_file.write('%s' % msg)\n",
    "\n",
    "    net['F'].train()\n",
    "    net['G'].train()\n",
    "\n",
    "    return eval_results[0]['Mean IoU']\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "from util.util import tensor2lab\n",
    "def display_imgs(images, epoch, i, subset='train', do_save=0):\n",
    "    if opt.display_id <= 0 and opt.no_html:\n",
    "        return\n",
    "\n",
    "    for k, im in images.items():\n",
    "        if 'y' in k:\n",
    "            images[k] = tensor2lab(im, val_loader.dataset.label2color) # 3HW\n",
    "        elif 'x' in k:\n",
    "            images[k] = im[0] # 3HW\n",
    "            d_mean = torch.FloatTensor(val_loader.dataset.mean).view(-1,1,1) # (3) -> (3,1,1)\n",
    "            d_std = torch.FloatTensor(val_loader.dataset.std).view(-1,1,1)\n",
    "            images[k] *= d_std\n",
    "            images[k] += d_mean\n",
    "            images[k] = images[k].mul(255).clamp(0,255).byte().numpy() # 3HW\n",
    "    visualizer.display_current_results(images, epoch, i, subset=subset, do_save=do_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StageF: F:2,G:0,D:0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load net[F] from ./checkpoints/xyx_10_cityscapesAB_b4/stageF:2,G:0,D:0/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.000/netF.pth\n",
      "===> Create results directory: ./checkpoints/xyx_10_cityscapesAB_b4/stageF:2,G:0,D:0/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.000/results\n",
      "==> OPTIONS:\n",
      "xyx_train.py --name xyx_10 --checkpoints_dir ./checkpoints --output_nc 20 --dataset cityscapesAB --batchSize 4 --heightSize 224 --widthSize 224 --start_epoch 0 --niter 200 --drop_lr 5 --resize_or_crop crop --ignore_index 0 --unsup_portion 89 --portion_total 90 --unsup_sampler sep --port 1235 --gpu_ids 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hushell/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL at epoch 999 ==> average CE = 5.102\n",
      "EVAL at epoch 999 [500 images in 19.51 sec] ==> {'Overall Acc': 0.8027315087968822, 'Mean Acc': 0.29677005481120045, 'FreqW Acc': 0.6879863908231599, 'Mean IoU': 0.23759327801778088}\n",
      "Per-class IoU:\n",
      "unlabeled: nan\n",
      "road: 0.89\n",
      "sidewalk: 0.41\n",
      "building: 0.66\n",
      "wall: 0.03\n",
      "fence: 0.03\n",
      "pole: 0.08\n",
      "traffic light: 0.01\n",
      "traffic sign: 0.03\n",
      "vegetation: 0.69\n",
      "terrain: 0.13\n",
      "sky: 0.74\n",
      "person: 0.14\n",
      "rider: 0.00\n",
      "car: 0.57\n",
      "truck: 0.02\n",
      "bus: 0.04\n",
      "train: 0.00\n",
      "motorcycle: 0.00\n",
      "bicycle: 0.05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space_sdd/hus/pytorch_dir/semisup_semantic/util/meter.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/space_sdd/hus/pytorch_dir/semisup_semantic/util/meter.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "# stage F\n",
    "stage_str = 'F:2,G:0,D:0'\n",
    "lr_F = 1e-4\n",
    "lr_GD = 1e-4\n",
    "lrFGD = '%.1e,%.1e,%.1e' % (lr_F, lr_GD, lr_GD)\n",
    "lb = 1.0\n",
    "\n",
    "name_temp = name_temp1 if lb >= 1e-2 else name_temp2\n",
    "opt.name =  name_temp % (exp_folder, stage_str, lrFGD, lb)\n",
    "ckpt_path = './checkpoints/%s' % opt.name\n",
    "\n",
    "load_nets(ckpt_path) # load net ckpts\n",
    "\n",
    "# Visualizer\n",
    "visualizer = Visualizer(opt) # recreate it since opt.name changes\n",
    "\n",
    "evaluation(999, do_G=False, subset='val')\n",
    "visualizer.save_webpage(prefix='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/xyx_10_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.000\n",
      "Load net[F] from ./checkpoints/xyx_10_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.000/netF.pth\n",
      "Load net[G] from ./checkpoints/xyx_10_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.000/netG.pth\n",
      "Load net[D] from ./checkpoints/xyx_10_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.000/netD.pth\n",
      "===> Create results directory: ./checkpoints/xyx_10_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.000/results\n",
      "==> OPTIONS:\n",
      "xyx_train.py --name xyx_10 --checkpoints_dir ./checkpoints --output_nc 20 --dataset cityscapesAB --batchSize 4 --heightSize 224 --widthSize 224 --start_epoch 0 --niter 200 --drop_lr 5 --resize_or_crop crop --ignore_index 0 --unsup_portion 89 --portion_total 90 --unsup_sampler sep --port 1235 --gpu_ids 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hushell/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL at epoch 999 ==> average CE = 5.102\n",
      "EVAL at epoch 999 [500 images in 32.93 sec] ==> {'Overall Acc': 0.8027315087968822, 'Mean Acc': 0.29677005481120045, 'FreqW Acc': 0.6879863908231599, 'Mean IoU': 0.23759327801778088}\n",
      "Per-class IoU:\n",
      "unlabeled: nan\n",
      "road: 0.89\n",
      "sidewalk: 0.41\n",
      "building: 0.66\n",
      "wall: 0.03\n",
      "fence: 0.03\n",
      "pole: 0.08\n",
      "traffic light: 0.01\n",
      "traffic sign: 0.03\n",
      "vegetation: 0.69\n",
      "terrain: 0.13\n",
      "sky: 0.74\n",
      "person: 0.14\n",
      "rider: 0.00\n",
      "car: 0.57\n",
      "truck: 0.02\n",
      "bus: 0.04\n",
      "train: 0.00\n",
      "motorcycle: 0.00\n",
      "bicycle: 0.05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space_sdd/hus/pytorch_dir/semisup_semantic/util/meter.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/space_sdd/hus/pytorch_dir/semisup_semantic/util/meter.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "# stage GD\n",
    "stage_str = 'F:1,G:2,D:2'\n",
    "lr_F = 1e-4\n",
    "lr_GD = 1e-4\n",
    "lrFGD = '%.1e,%.1e,%.1e' % (lr_F, lr_GD, lr_GD)\n",
    "lb = 1.0\n",
    "\n",
    "name_temp = name_temp1 if lb >= 1e-2 else name_temp2\n",
    "opt.name =  name_temp % (exp_folder, stage_str, lrFGD, lb)\n",
    "ckpt_path = './checkpoints/%s' % opt.name\n",
    "print(ckpt_path)\n",
    "\n",
    "load_nets(ckpt_path) # load net ckpts\n",
    "\n",
    "# Visualizer\n",
    "visualizer = Visualizer(opt) # recreate it since opt.name changes\n",
    "\n",
    "evaluation(999, do_G=True, subset='val')\n",
    "visualizer.save_webpage(prefix='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/xyx_10_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX0.010\n",
      "Load net[F] from ./checkpoints/xyx_10_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX0.010/netF.pth\n",
      "Load net[G] from ./checkpoints/xyx_10_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX0.010/netG.pth\n",
      "Load net[D] from ./checkpoints/xyx_10_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX0.010/netD.pth\n",
      "===> Create results directory: ./checkpoints/xyx_10_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX0.010/results\n",
      "==> OPTIONS:\n",
      "xyx_train.py --name xyx_10 --checkpoints_dir ./checkpoints --output_nc 20 --dataset cityscapesAB --batchSize 4 --heightSize 224 --widthSize 224 --start_epoch 0 --niter 200 --drop_lr 5 --resize_or_crop crop --ignore_index 0 --unsup_portion 89 --portion_total 90 --unsup_sampler sep --port 1235 --gpu_ids 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hushell/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL at epoch 999 ==> average CE = 5.698\n",
      "EVAL at epoch 999 [500 images in 32.54 sec] ==> {'Overall Acc': 0.8085365327797522, 'Mean Acc': 0.2938942303831505, 'FreqW Acc': 0.6916282011055124, 'Mean IoU': 0.24001680924636953}\n",
      "Per-class IoU:\n",
      "unlabeled: nan\n",
      "road: 0.89\n",
      "sidewalk: 0.40\n",
      "building: 0.67\n",
      "wall: 0.03\n",
      "fence: 0.03\n",
      "pole: 0.09\n",
      "traffic light: 0.01\n",
      "traffic sign: 0.03\n",
      "vegetation: 0.70\n",
      "terrain: 0.13\n",
      "sky: 0.74\n",
      "person: 0.15\n",
      "rider: 0.00\n",
      "car: 0.58\n",
      "truck: 0.02\n",
      "bus: 0.05\n",
      "train: 0.00\n",
      "motorcycle: 0.00\n",
      "bicycle: 0.04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space_sdd/hus/pytorch_dir/semisup_semantic/util/meter.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/space_sdd/hus/pytorch_dir/semisup_semantic/util/meter.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "# stage F2\n",
    "stage_str = 'F:2,G:1,D:1'\n",
    "lr_F = 1e-4\n",
    "lr_GD = 1e-4\n",
    "lrFGD = '%.1e,%.1e,%.1e' % (lr_F, lr_GD, lr_GD)\n",
    "lb = 1e-2\n",
    "\n",
    "name_temp = name_temp1 if lb >= 1e-2 else name_temp2\n",
    "opt.name =  name_temp % (exp_folder, stage_str, lrFGD, lb)\n",
    "ckpt_path = './checkpoints/%s' % opt.name\n",
    "print(ckpt_path)\n",
    "\n",
    "load_nets(ckpt_path) # load net ckpts\n",
    "\n",
    "# Visualizer\n",
    "visualizer = Visualizer(opt) # recreate it since opt.name changes\n",
    "\n",
    "evaluation(999, do_G=True, subset='val')\n",
    "visualizer.save_webpage(prefix='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
