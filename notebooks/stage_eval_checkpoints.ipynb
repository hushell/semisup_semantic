{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = 'xyx_train.py --name xyx_2 --checkpoints_dir ./checkpoints --output_nc 20 --dataset cityscapesAB ' \\\n",
    "        + '--batchSize 4 --heightSize 224 --widthSize 224 --start_epoch 0 --niter 200 ' \\\n",
    "        + '--drop_lr 5 --resize_or_crop crop --ignore_index 0 --unsup_portion 89 --portion_total 90 ' \\\n",
    "        + '--unsup_sampler sep --port 1235 --gpu_ids 1'\n",
    "sys.argv = sys.argv.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(archD='patch', archF='style_transform', archG='style_transform', batchSize=4, beta1=0.5, checkpoints_dir='./checkpoints', dataset='cityscapesAB', display_id=1, display_winsize=256, drop_lr=5, gpu_ids='1', heightSize=224, ignore_index=0, input_nc=3, isTrain=True, lambda_x=1.0, lambda_y=1.0, lr=0.0002, lrFGD={'F': 0.0001, 'G': 0.0001, 'D': 0.0001}, manual_seed=123, nThreads=4, n_layers_D=3, n_layers_F=9, n_layers_G=9, name='xyx_2_cityscapesAB_b4/stageF:2,G:0,D:0/lrFGD1e-4,1e-4,1e-4_lbX1.0e+00', ndf=64, ngf=64, niter=200, niter_decay=100, no_flip=False, no_html=False, noise='sphere', nz=100, output_nc=20, port=1235, portion_total=90, resize_or_crop='crop', save_every=2, stage='F:2,G:0,D:0', start_epoch=0, unsup_portion=89, unsup_sampler='sep', updates={'F': 2, 'G': 0, 'D': 0}, use_dropout=False, which_direction='AtoB', widthSize=224)\n"
     ]
    }
   ],
   "source": [
    "from xyx_nets import *\n",
    "\n",
    "opt = get_opt()\n",
    "print(opt)\n",
    "\n",
    "# gpu id\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_ids # absolute ids\n",
    "if len(opt.gpu_ids) > 0:\n",
    "    torch.randn(8).cuda()\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "opt.gpu_ids = range(0,len(opt.gpu_ids)) # new range starting from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xyx_2_cityscapesAB_b4\n"
     ]
    }
   ],
   "source": [
    "#name_temp1 = '%s/stage%s/lrFGD%s_lbX%.3f'\n",
    "name_temp1 = '%s/stage%s/lrFGD%s_lbX%.1e'\n",
    "name_temp2 = '%s/stage%s/lrFGD%s_lbX%.1e'\n",
    "exp_folder = opt.name.split('/')[0]\n",
    "print(exp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses\n",
    "CE, L1 = create_losses(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> dataset [CityscapesABDataset] was created\n"
     ]
    }
   ],
   "source": [
    "# data_loaders\n",
    "from data.data_loader import CreateDataLoader,InfiniteDataLoader,XYDataLoader\n",
    "from util.visualizer import Visualizer\n",
    "\n",
    "opt.phase = 'val'\n",
    "opt.isTrain = False\n",
    "val_loader = CreateDataLoader(opt)\n",
    "opt = val_loader.update_opt(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networks\n",
    "TAU0 = 1.0\n",
    "\n",
    "net =dict()\n",
    "net['F'] = FX2Y(opt, temperature=TAU0)\n",
    "net['G'] = GY2X(opt)\n",
    "net['D'] = NLayerDiscriminator(opt)\n",
    "\n",
    "for k in net.keys():\n",
    "    if len(opt.gpu_ids) > 0:\n",
    "        net[k].cuda(opt.gpu_ids[0])\n",
    "    # F has its own init\n",
    "    if k != 'F':\n",
    "        net[k].apply(weights_init)\n",
    "\n",
    "def load_nets(ckpt_path):\n",
    "    for k in net.keys():\n",
    "        # load if found saved weights\n",
    "        weights_fpath = os.path.join(ckpt_path, 'net%s.pth' % (k))\n",
    "        if os.path.exists(weights_fpath):\n",
    "            print('Load net[%s] from %s' % (k, weights_fpath))\n",
    "            net[k].load_state_dict(torch.load(weights_fpath, map_location=lambda storage, loc: storage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.meter import SegmentationMeter\n",
    "\n",
    "def evaluation(epoch, do_G=False, subset='train'):\n",
    "    heightSize = val_loader.dataset.heightSize\n",
    "    widthSize = val_loader.dataset.widthSize\n",
    "    xx = torch.FloatTensor(1, opt.input_nc, heightSize, widthSize)\n",
    "    yy_int = torch.LongTensor(1, heightSize, widthSize)\n",
    "    if len(opt.gpu_ids) > 0:\n",
    "        xx = xx.cuda(opt.gpu_ids[0])\n",
    "        yy_int = yy_int.cuda(opt.gpu_ids[0])\n",
    "        \n",
    "    def one_hot(y_int):\n",
    "        y_temp = y_int.unsqueeze(dim=1)\n",
    "        y = torch.FloatTensor(1, opt.output_nc, heightSize, widthSize)\n",
    "        if len(opt.gpu_ids) > 0:\n",
    "            y = y.cuda()\n",
    "        y.zero_().scatter_(1, y_temp, 1)\n",
    "        return y\n",
    "\n",
    "    net['F'].eval()\n",
    "    if do_G:\n",
    "        net['G'].eval()\n",
    "\n",
    "    eval_stats = SegmentationMeter(n_class=opt.output_nc, ignore_index=opt.ignore_index)\n",
    "    E_loss_CE = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    val_loader_iter = iter(val_loader)\n",
    "    for i in range(len(val_loader)):\n",
    "        populate_xy(xx, yy_int, val_loader_iter, opt)\n",
    "        v_x = Variable(xx, volatile=True)\n",
    "        v_y_int = Variable(yy_int, volatile=True)\n",
    "        y_hat = net['F'](v_x)\n",
    "        E_loss_CE.append( CE(y_hat, v_y_int) )\n",
    "        logits = y_hat.data.cpu().numpy()\n",
    "        pred = logits.argmax(1) # NCHW -> NHW\n",
    "        gt = yy_int.cpu().numpy()\n",
    "        eval_stats.update_confmat(gt, pred)\n",
    "\n",
    "        if do_G:\n",
    "            x_tilde = net['G'](y_hat) # x -> y_hat -> x_tilde\n",
    "            v_y = Variable( one_hot(yy_int) )\n",
    "            log_y = noise_log_y(v_y, 0.5, opt.gpu_ids)\n",
    "            x_hat = net['G']( log_y )\n",
    "\n",
    "        # visualization\n",
    "        if i % 10 == 0:\n",
    "            images = {'TEST_x':v_x.data.cpu(),\n",
    "                      'TEST_y':v_y_int.data.cpu().numpy(), 'TEST_y_hat':y_hat.data.cpu().numpy().argmax(1)}\n",
    "            if do_G:\n",
    "                images['TEST_x_tilde'] = x_tilde.data.cpu()\n",
    "                images['TEST_x_hat'] = x_hat.data.cpu()\n",
    "            display_imgs(images, epoch, i, subset=subset, do_save=2)\n",
    "\n",
    "    print('EVAL at epoch %d ==> average CE = %.3f' % (epoch, sum(E_loss_CE).data[0] / len(val_loader)))\n",
    "    eval_results = eval_stats.get_eval_results()\n",
    "    msg = 'EVAL at epoch %d [%d images in %.2f sec] ==> %s\\n' % \\\n",
    "                (epoch, len(val_loader), time.time()-start_time, eval_results[0])\n",
    "    msg += 'Per-class IoU:\\n'\n",
    "    msg += ''.join(['%s: %.2f\\n' % (cname,ciu)\n",
    "                    for cname,ciu in zip(val_loader.dataset.label2name, eval_results[1])])\n",
    "    print(msg)\n",
    "    with open(visualizer.log_name, \"a\") as log_file:\n",
    "        log_file.write('%s' % msg)\n",
    "\n",
    "    net['F'].train()\n",
    "    net['G'].train()\n",
    "\n",
    "    return eval_results[0]['Mean IoU']\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "from util.util import tensor2lab\n",
    "def display_imgs(images, epoch, i, subset='train', do_save=0):\n",
    "    if opt.display_id <= 0 and opt.no_html:\n",
    "        return\n",
    "\n",
    "    for k, im in images.items():\n",
    "        if 'y' in k:\n",
    "            images[k] = tensor2lab(im, val_loader.dataset.label2color) # 3HW\n",
    "        elif 'x' in k:\n",
    "            images[k] = im[0] # 3HW\n",
    "            d_mean = torch.FloatTensor(val_loader.dataset.mean).view(-1,1,1) # (3) -> (3,1,1)\n",
    "            d_std = torch.FloatTensor(val_loader.dataset.std).view(-1,1,1)\n",
    "            images[k] *= d_std\n",
    "            images[k] += d_mean\n",
    "            images[k] = images[k].mul(255).clamp(0,255).byte().numpy() # 3HW\n",
    "    visualizer.display_current_results(images, epoch, i, subset=subset, do_save=do_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StageF: F:2,G:0,D:0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load net[F] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:0,D:0/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e+00/netF.pth\n",
      "===> Create results directory: ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:0,D:0/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e+00/results\n",
      "==> OPTIONS:\n",
      "xyx_train.py --name xyx_2 --checkpoints_dir ./checkpoints --output_nc 20 --dataset cityscapesAB --batchSize 4 --heightSize 224 --widthSize 224 --start_epoch 0 --niter 200 --drop_lr 5 --resize_or_crop crop --ignore_index 0 --unsup_portion 89 --portion_total 90 --unsup_sampler sep --port 1235 --gpu_ids 1\n",
      "\n",
      "EVAL at epoch 999 ==> average CE = 2.378\n",
      "EVAL at epoch 999 [500 images in 17.39 sec] ==> {'Overall Acc': 0.800828480753698, 'Mean Acc': 0.30085420517081646, 'FreqW Acc': 0.6867478359092789, 'Mean IoU': 0.2400811374317964}\n",
      "Per-class IoU:\n",
      "unlabeled: nan\n",
      "road: 0.89\n",
      "sidewalk: 0.40\n",
      "building: 0.66\n",
      "wall: 0.03\n",
      "fence: 0.03\n",
      "pole: 0.07\n",
      "traffic light: 0.01\n",
      "traffic sign: 0.03\n",
      "vegetation: 0.68\n",
      "terrain: 0.14\n",
      "sky: 0.75\n",
      "person: 0.16\n",
      "rider: 0.00\n",
      "car: 0.58\n",
      "truck: 0.02\n",
      "bus: 0.06\n",
      "train: 0.00\n",
      "motorcycle: 0.00\n",
      "bicycle: 0.04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hushell/working/my_work_semisup/semisup_semantic/util/meter.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/home/hushell/working/my_work_semisup/semisup_semantic/util/meter.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "# stage F\n",
    "stage_str = 'F:2,G:0,D:0'\n",
    "lr_F = 1e-4\n",
    "lr_GD = 1e-4\n",
    "lrFGD = '%.1e,%.1e,%.1e' % (lr_F, lr_GD, lr_GD)\n",
    "lb = 1.0\n",
    "\n",
    "name_temp = name_temp1 if lb >= 1e-2 else name_temp2\n",
    "opt.name =  name_temp % (exp_folder, stage_str, lrFGD, lb)\n",
    "ckpt_path = './checkpoints/%s' % opt.name\n",
    "\n",
    "load_nets(ckpt_path) # load net ckpts\n",
    "\n",
    "# Visualizer\n",
    "visualizer = Visualizer(opt) # recreate it since opt.name changes\n",
    "\n",
    "evaluation(999, do_G=False, subset='val')\n",
    "visualizer.save_webpage(prefix='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/xyx_2_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e+00\n",
      "Load net[F] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e+00/netF.pth\n",
      "Load net[G] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e+00/netG.pth\n",
      "Load net[D] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e+00/netD.pth\n",
      "===> Create results directory: ./checkpoints/xyx_2_cityscapesAB_b4/stageF:1,G:2,D:2/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e+00/results\n",
      "==> OPTIONS:\n",
      "xyx_train.py --name xyx_2 --checkpoints_dir ./checkpoints --output_nc 20 --dataset cityscapesAB --batchSize 4 --heightSize 224 --widthSize 224 --start_epoch 0 --niter 200 --drop_lr 5 --resize_or_crop crop --ignore_index 0 --unsup_portion 89 --portion_total 90 --unsup_sampler sep --port 1235 --gpu_ids 1\n",
      "\n",
      "EVAL at epoch 999 ==> average CE = 2.378\n",
      "EVAL at epoch 999 [500 images in 53.72 sec] ==> {'Overall Acc': 0.800828480753698, 'Mean Acc': 0.30085420517081646, 'FreqW Acc': 0.6867478359092789, 'Mean IoU': 0.2400811374317964}\n",
      "Per-class IoU:\n",
      "unlabeled: nan\n",
      "road: 0.89\n",
      "sidewalk: 0.40\n",
      "building: 0.66\n",
      "wall: 0.03\n",
      "fence: 0.03\n",
      "pole: 0.07\n",
      "traffic light: 0.01\n",
      "traffic sign: 0.03\n",
      "vegetation: 0.68\n",
      "terrain: 0.14\n",
      "sky: 0.75\n",
      "person: 0.16\n",
      "rider: 0.00\n",
      "car: 0.58\n",
      "truck: 0.02\n",
      "bus: 0.06\n",
      "train: 0.00\n",
      "motorcycle: 0.00\n",
      "bicycle: 0.04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hushell/working/my_work_semisup/semisup_semantic/util/meter.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/home/hushell/working/my_work_semisup/semisup_semantic/util/meter.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "# stage GD\n",
    "stage_str = 'F:1,G:2,D:2'\n",
    "lr_F = 1e-4\n",
    "lr_GD = 1e-4\n",
    "lrFGD = '%.1e,%.1e,%.1e' % (lr_F, lr_GD, lr_GD)\n",
    "lb = 1.0\n",
    "\n",
    "name_temp = name_temp1 if lb >= 1e-2 else name_temp2\n",
    "opt.name =  name_temp % (exp_folder, stage_str, lrFGD, lb)\n",
    "ckpt_path = './checkpoints/%s' % opt.name\n",
    "print(ckpt_path)\n",
    "\n",
    "load_nets(ckpt_path) # load net ckpts\n",
    "\n",
    "# Visualizer\n",
    "visualizer = Visualizer(opt) # recreate it since opt.name changes\n",
    "\n",
    "evaluation(999, do_G=True, subset='val')\n",
    "visualizer.save_webpage(prefix='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e-04\n",
      "Load net[F] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e-04/netF.pth\n",
      "Load net[G] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e-04/netG.pth\n",
      "Load net[D] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e-04/netD.pth\n",
      "===> Create results directory: ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:1,D:1/lrFGD1.0e-04,1.0e-04,1.0e-04_lbX1.0e-04/results\n",
      "==> OPTIONS:\n",
      "xyx_train.py --name xyx_2 --checkpoints_dir ./checkpoints --output_nc 20 --dataset cityscapesAB --batchSize 4 --heightSize 224 --widthSize 224 --start_epoch 0 --niter 200 --drop_lr 5 --resize_or_crop crop --ignore_index 0 --unsup_portion 89 --portion_total 90 --unsup_sampler sep --port 1235 --gpu_ids 1\n",
      "\n",
      "EVAL at epoch 999 ==> average CE = 3.225\n",
      "EVAL at epoch 999 [500 images in 54.83 sec] ==> {'Overall Acc': 0.801128161968242, 'Mean Acc': 0.30473099702657785, 'FreqW Acc': 0.6903762476327117, 'Mean IoU': 0.24147805067482658}\n",
      "Per-class IoU:\n",
      "unlabeled: nan\n",
      "road: 0.89\n",
      "sidewalk: 0.42\n",
      "building: 0.66\n",
      "wall: 0.03\n",
      "fence: 0.03\n",
      "pole: 0.07\n",
      "traffic light: 0.01\n",
      "traffic sign: 0.03\n",
      "vegetation: 0.69\n",
      "terrain: 0.14\n",
      "sky: 0.75\n",
      "person: 0.15\n",
      "rider: 0.00\n",
      "car: 0.57\n",
      "truck: 0.02\n",
      "bus: 0.05\n",
      "train: 0.00\n",
      "motorcycle: 0.01\n",
      "bicycle: 0.05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hushell/working/my_work_semisup/semisup_semantic/util/meter.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/home/hushell/working/my_work_semisup/semisup_semantic/util/meter.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "# stage F2\n",
    "stage_str = 'F:2,G:1,D:1'\n",
    "lr_F = 1e-4\n",
    "lr_GD = 1e-4\n",
    "lrFGD = '%.1e,%.1e,%.1e' % (lr_F, lr_GD, lr_GD)\n",
    "lb = 1e-4\n",
    "\n",
    "name_temp = name_temp1 if lb >= 1e-2 else name_temp2\n",
    "opt.name =  name_temp % (exp_folder, stage_str, lrFGD, lb)\n",
    "ckpt_path = './checkpoints/%s' % opt.name\n",
    "print(ckpt_path)\n",
    "\n",
    "load_nets(ckpt_path) # load net ckpts\n",
    "\n",
    "# Visualizer\n",
    "visualizer = Visualizer(opt) # recreate it since opt.name changes\n",
    "\n",
    "evaluation(999, do_G=True, subset='val')\n",
    "visualizer.save_webpage(prefix='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:2,D:2/lrFGD1.0e-04,1.0e+00,1.0e+00_lbX1.0e-04\n",
      "Load net[F] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:2,D:2/lrFGD1.0e-04,1.0e+00,1.0e+00_lbX1.0e-04/netF.pth\n",
      "Load net[G] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:2,D:2/lrFGD1.0e-04,1.0e+00,1.0e+00_lbX1.0e-04/netG.pth\n",
      "Load net[D] from ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:2,D:2/lrFGD1.0e-04,1.0e+00,1.0e+00_lbX1.0e-04/netD.pth\n",
      "===> Create results directory: ./checkpoints/xyx_2_cityscapesAB_b4/stageF:2,G:2,D:2/lrFGD1.0e-04,1.0e+00,1.0e+00_lbX1.0e-04/results\n",
      "==> OPTIONS:\n",
      "xyx_train.py --name xyx_2 --checkpoints_dir ./checkpoints --output_nc 20 --dataset cityscapesAB --batchSize 4 --heightSize 224 --widthSize 224 --start_epoch 0 --niter 200 --drop_lr 5 --resize_or_crop crop --ignore_index 0 --unsup_portion 89 --portion_total 90 --unsup_sampler sep --port 1235 --gpu_ids 1\n",
      "\n",
      "EVAL at epoch 999 ==> average CE = 4.082\n",
      "EVAL at epoch 999 [500 images in 51.82 sec] ==> {'Overall Acc': 0.8024606095383332, 'Mean Acc': 0.30424662126081015, 'FreqW Acc': 0.6882607594418478, 'Mean IoU': 0.24222631984524534}\n",
      "Per-class IoU:\n",
      "unlabeled: nan\n",
      "road: 0.88\n",
      "sidewalk: 0.40\n",
      "building: 0.67\n",
      "wall: 0.03\n",
      "fence: 0.03\n",
      "pole: 0.09\n",
      "traffic light: 0.01\n",
      "traffic sign: 0.03\n",
      "vegetation: 0.69\n",
      "terrain: 0.14\n",
      "sky: 0.75\n",
      "person: 0.16\n",
      "rider: 0.00\n",
      "car: 0.58\n",
      "truck: 0.02\n",
      "bus: 0.07\n",
      "train: 0.00\n",
      "motorcycle: 0.01\n",
      "bicycle: 0.05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hushell/working/my_work_semisup/semisup_semantic/util/meter.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
      "/home/hushell/working/my_work_semisup/semisup_semantic/util/meter.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n"
     ]
    }
   ],
   "source": [
    "stage_str = 'F:2,G:2,D:2'\n",
    "lr_F = 1e-4\n",
    "lr_GD = 1e-4\n",
    "lb = 1e-4\n",
    "lrFGD = '%.1e,%.1e,%.1e' % (lr_F, lr_GD/lb, lr_GD/lb)\n",
    "\n",
    "name_temp = name_temp1 if lb >= 1e-2 else name_temp2\n",
    "opt.name =  name_temp % (exp_folder, stage_str, lrFGD, lb)\n",
    "ckpt_path = './checkpoints/%s' % opt.name\n",
    "print(ckpt_path)\n",
    "\n",
    "load_nets(ckpt_path) # load net ckpts\n",
    "\n",
    "# Visualizer\n",
    "visualizer = Visualizer(opt) # recreate it since opt.name changes\n",
    "\n",
    "evaluation(999, do_G=True, subset='val')\n",
    "visualizer.save_webpage(prefix='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
